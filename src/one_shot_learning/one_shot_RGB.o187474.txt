/gpfs/workdir/dunoyerg/output_faces_rgb.csv /gpfs/workdir/dunoyerg/photos_apprentissage_visage_rgb/ /gpfs/workdir/dunoyerg/output_print/faces_187474.csv /gpfs/workdir/dunoyerg/output_print/faces_187474.csv
device : cuda:0
441694
3816
##############################
no DataParallel
Working on model =   batch size: 256 epochs: 0 lr: 0.1
Train Epoch: 0 [0/441694 (0%)]	Loss: 0.760129
Train Epoch: 0 [12800/441694 (3%)]	Loss: 0.680561
Train Epoch: 0 [25600/441694 (6%)]	Loss: 0.619444
Train Epoch: 0 [38400/441694 (9%)]	Loss: 0.635989
Train Epoch: 0 [51200/441694 (12%)]	Loss: 0.577591
Train Epoch: 0 [64000/441694 (14%)]	Loss: 0.596198
Train Epoch: 0 [76800/441694 (17%)]	Loss: 0.563188
Train Epoch: 0 [89600/441694 (20%)]	Loss: 0.569497
Train Epoch: 0 [102400/441694 (23%)]	Loss: 0.595063
Train Epoch: 0 [115200/441694 (26%)]	Loss: 0.539224
Train Epoch: 0 [128000/441694 (29%)]	Loss: 0.609698
Train Epoch: 0 [140800/441694 (32%)]	Loss: 0.561350
Train Epoch: 0 [153600/441694 (35%)]	Loss: 0.543105
Train Epoch: 0 [166400/441694 (38%)]	Loss: 0.573314
Train Epoch: 0 [179200/441694 (41%)]	Loss: 0.574035
Train Epoch: 0 [192000/441694 (43%)]	Loss: 0.532903
Train Epoch: 0 [204800/441694 (46%)]	Loss: 0.515949
Train Epoch: 0 [217600/441694 (49%)]	Loss: 0.585628
Train Epoch: 0 [230400/441694 (52%)]	Loss: 0.559722
Train Epoch: 0 [243200/441694 (55%)]	Loss: 0.521793
Train Epoch: 0 [256000/441694 (58%)]	Loss: 0.572962
Train Epoch: 0 [268800/441694 (61%)]	Loss: 0.584337
Train Epoch: 0 [281600/441694 (64%)]	Loss: 0.554412
Train Epoch: 0 [294400/441694 (67%)]	Loss: 0.551363
Train Epoch: 0 [307200/441694 (70%)]	Loss: 0.530403
Train Epoch: 0 [320000/441694 (72%)]	Loss: 0.557054
Train Epoch: 0 [332800/441694 (75%)]	Loss: 0.564760
Train Epoch: 0 [345600/441694 (78%)]	Loss: 0.537212
Train Epoch: 0 [358400/441694 (81%)]	Loss: 0.520492
Train Epoch: 0 [371200/441694 (84%)]	Loss: 0.570409
Train Epoch: 0 [384000/441694 (87%)]	Loss: 0.561888
Train Epoch: 0 [396800/441694 (90%)]	Loss: 0.562828
Train Epoch: 0 [409600/441694 (93%)]	Loss: 0.533671
Train Epoch: 0 [422400/441694 (96%)]	Loss: 0.533523
Train Epoch: 0 [435200/441694 (98%)]	Loss: 0.526883

 train set: Average loss: 0.0022, Accuracy: 323298/441694 (73%)


 test set: Average loss: 0.0021, Accuracy: 2888/3816 (76%)

Working on model =   batch size: 256 epochs: 1 lr: 0.1
Train Epoch: 1 [0/441694 (0%)]	Loss: 0.573393
Train Epoch: 1 [12800/441694 (3%)]	Loss: 0.534851
Train Epoch: 1 [25600/441694 (6%)]	Loss: 0.537261
Train Epoch: 1 [38400/441694 (9%)]	Loss: 0.534348
Train Epoch: 1 [51200/441694 (12%)]	Loss: 0.528066
Train Epoch: 1 [64000/441694 (14%)]	Loss: 0.530681
Train Epoch: 1 [76800/441694 (17%)]	Loss: 0.572404
Train Epoch: 1 [89600/441694 (20%)]	Loss: 0.523870
Train Epoch: 1 [102400/441694 (23%)]	Loss: 0.525962
Train Epoch: 1 [115200/441694 (26%)]	Loss: 0.567714
Train Epoch: 1 [128000/441694 (29%)]	Loss: 0.557272
Train Epoch: 1 [140800/441694 (32%)]	Loss: 0.542750
Train Epoch: 1 [153600/441694 (35%)]	Loss: 0.576265
Train Epoch: 1 [166400/441694 (38%)]	Loss: 0.552714
Train Epoch: 1 [179200/441694 (41%)]	Loss: 0.547161
Train Epoch: 1 [192000/441694 (43%)]	Loss: 0.549783
Train Epoch: 1 [204800/441694 (46%)]	Loss: 0.528455
Train Epoch: 1 [217600/441694 (49%)]	Loss: 0.513270
Train Epoch: 1 [230400/441694 (52%)]	Loss: 0.534852
Train Epoch: 1 [243200/441694 (55%)]	Loss: 0.525940
Train Epoch: 1 [256000/441694 (58%)]	Loss: 0.567890
Train Epoch: 1 [268800/441694 (61%)]	Loss: 0.518419
Train Epoch: 1 [281600/441694 (64%)]	Loss: 0.522912
Train Epoch: 1 [294400/441694 (67%)]	Loss: 0.513407
Train Epoch: 1 [307200/441694 (70%)]	Loss: 0.475411
Train Epoch: 1 [320000/441694 (72%)]	Loss: 0.528956
Train Epoch: 1 [332800/441694 (75%)]	Loss: 0.517602
Train Epoch: 1 [345600/441694 (78%)]	Loss: 0.530365
Train Epoch: 1 [358400/441694 (81%)]	Loss: 0.557028
Train Epoch: 1 [371200/441694 (84%)]	Loss: 0.530757
Train Epoch: 1 [384000/441694 (87%)]	Loss: 0.524448
Train Epoch: 1 [396800/441694 (90%)]	Loss: 0.526574
Train Epoch: 1 [409600/441694 (93%)]	Loss: 0.496402
Train Epoch: 1 [422400/441694 (96%)]	Loss: 0.536514
Train Epoch: 1 [435200/441694 (98%)]	Loss: 0.524884

 train set: Average loss: 0.0020, Accuracy: 348116/441694 (79%)


 test set: Average loss: 0.0024, Accuracy: 2600/3816 (68%)

Working on model =   batch size: 256 epochs: 2 lr: 0.1
Train Epoch: 2 [0/441694 (0%)]	Loss: 0.528653
Train Epoch: 2 [12800/441694 (3%)]	Loss: 0.531089
Train Epoch: 2 [25600/441694 (6%)]	Loss: 0.490625
Train Epoch: 2 [38400/441694 (9%)]	Loss: 0.542951
Train Epoch: 2 [51200/441694 (12%)]	Loss: 0.545033
Train Epoch: 2 [64000/441694 (14%)]	Loss: 0.528437
Train Epoch: 2 [76800/441694 (17%)]	Loss: 0.507735
Train Epoch: 2 [89600/441694 (20%)]	Loss: 0.559317
Train Epoch: 2 [102400/441694 (23%)]	Loss: 0.480722
Train Epoch: 2 [115200/441694 (26%)]	Loss: 0.542421
Train Epoch: 2 [128000/441694 (29%)]	Loss: 0.552560
Train Epoch: 2 [140800/441694 (32%)]	Loss: 0.537571
Train Epoch: 2 [153600/441694 (35%)]	Loss: 0.540204
Train Epoch: 2 [166400/441694 (38%)]	Loss: 0.565377
Train Epoch: 2 [179200/441694 (41%)]	Loss: 0.523391
Train Epoch: 2 [192000/441694 (43%)]	Loss: 0.520782
Train Epoch: 2 [204800/441694 (46%)]	Loss: 0.546609
Train Epoch: 2 [217600/441694 (49%)]	Loss: 0.549875
Train Epoch: 2 [230400/441694 (52%)]	Loss: 0.513980
Train Epoch: 2 [243200/441694 (55%)]	Loss: 0.550830
Train Epoch: 2 [256000/441694 (58%)]	Loss: 0.505820
Train Epoch: 2 [268800/441694 (61%)]	Loss: 0.490106
Train Epoch: 2 [281600/441694 (64%)]	Loss: 0.530926
Train Epoch: 2 [294400/441694 (67%)]	Loss: 0.477680
Train Epoch: 2 [307200/441694 (70%)]	Loss: 0.504510
Train Epoch: 2 [320000/441694 (72%)]	Loss: 0.531049
Train Epoch: 2 [332800/441694 (75%)]	Loss: 0.483028
Train Epoch: 2 [345600/441694 (78%)]	Loss: 0.556673
Train Epoch: 2 [358400/441694 (81%)]	Loss: 0.571429
Train Epoch: 2 [371200/441694 (84%)]	Loss: 0.554128
Train Epoch: 2 [384000/441694 (87%)]	Loss: 0.506497
Train Epoch: 2 [396800/441694 (90%)]	Loss: 0.505510
Train Epoch: 2 [409600/441694 (93%)]	Loss: 0.507157
Train Epoch: 2 [422400/441694 (96%)]	Loss: 0.564789
Train Epoch: 2 [435200/441694 (98%)]	Loss: 0.566662

 train set: Average loss: 0.0020, Accuracy: 354730/441694 (80%)


 test set: Average loss: 0.0024, Accuracy: 2592/3816 (68%)

Working on model =   batch size: 256 epochs: 3 lr: 0.1
Train Epoch: 3 [0/441694 (0%)]	Loss: 0.533974
Train Epoch: 3 [12800/441694 (3%)]	Loss: 0.552665
Train Epoch: 3 [25600/441694 (6%)]	Loss: 0.504614
Train Epoch: 3 [38400/441694 (9%)]	Loss: 0.520089
Train Epoch: 3 [51200/441694 (12%)]	Loss: 0.519421
Train Epoch: 3 [64000/441694 (14%)]	Loss: 0.520033
Train Epoch: 3 [76800/441694 (17%)]	Loss: 0.533408
Train Epoch: 3 [89600/441694 (20%)]	Loss: 0.522035
Train Epoch: 3 [102400/441694 (23%)]	Loss: 0.507169
Train Epoch: 3 [115200/441694 (26%)]	Loss: 0.535429
Train Epoch: 3 [128000/441694 (29%)]	Loss: 0.534533
Train Epoch: 3 [140800/441694 (32%)]	Loss: 0.532477
Train Epoch: 3 [153600/441694 (35%)]	Loss: 0.467975
Train Epoch: 3 [166400/441694 (38%)]	Loss: 0.499411
Train Epoch: 3 [179200/441694 (41%)]	Loss: 0.481457
Train Epoch: 3 [192000/441694 (43%)]	Loss: 0.482752
Train Epoch: 3 [204800/441694 (46%)]	Loss: 0.525048
Train Epoch: 3 [217600/441694 (49%)]	Loss: 0.519584
Train Epoch: 3 [230400/441694 (52%)]	Loss: 0.512430
Train Epoch: 3 [243200/441694 (55%)]	Loss: 0.469252
Train Epoch: 3 [256000/441694 (58%)]	Loss: 0.505138
Train Epoch: 3 [268800/441694 (61%)]	Loss: 0.524135
Train Epoch: 3 [281600/441694 (64%)]	Loss: 0.543458
Train Epoch: 3 [294400/441694 (67%)]	Loss: 0.519947
Train Epoch: 3 [307200/441694 (70%)]	Loss: 0.507662
Train Epoch: 3 [320000/441694 (72%)]	Loss: 0.504953
Train Epoch: 3 [332800/441694 (75%)]	Loss: 0.556569
Train Epoch: 3 [345600/441694 (78%)]	Loss: 0.504275
Train Epoch: 3 [358400/441694 (81%)]	Loss: 0.526210
Train Epoch: 3 [371200/441694 (84%)]	Loss: 0.549436
Train Epoch: 3 [384000/441694 (87%)]	Loss: 0.550273
Train Epoch: 3 [396800/441694 (90%)]	Loss: 0.490595
Train Epoch: 3 [409600/441694 (93%)]	Loss: 0.555340
Train Epoch: 3 [422400/441694 (96%)]	Loss: 0.492321
Train Epoch: 3 [435200/441694 (98%)]	Loss: 0.505458

 train set: Average loss: 0.0020, Accuracy: 355769/441694 (81%)


 test set: Average loss: 0.0025, Accuracy: 2456/3816 (64%)

Working on model =   batch size: 256 epochs: 4 lr: 0.1
Train Epoch: 4 [0/441694 (0%)]	Loss: 0.512094
Train Epoch: 4 [12800/441694 (3%)]	Loss: 0.521218
Train Epoch: 4 [25600/441694 (6%)]	Loss: 0.520441
Train Epoch: 4 [38400/441694 (9%)]	Loss: 0.506515
Train Epoch: 4 [51200/441694 (12%)]	Loss: 0.547056
Train Epoch: 4 [64000/441694 (14%)]	Loss: 0.572911
Train Epoch: 4 [76800/441694 (17%)]	Loss: 0.506924
Train Epoch: 4 [89600/441694 (20%)]	Loss: 0.517848
Train Epoch: 4 [102400/441694 (23%)]	Loss: 0.524183
Train Epoch: 4 [115200/441694 (26%)]	Loss: 0.560791
Train Epoch: 4 [128000/441694 (29%)]	Loss: 0.515434
Train Epoch: 4 [140800/441694 (32%)]	Loss: 0.516889
Train Epoch: 4 [153600/441694 (35%)]	Loss: 0.482667
Train Epoch: 4 [166400/441694 (38%)]	Loss: 0.535165
Train Epoch: 4 [179200/441694 (41%)]	Loss: 0.542561
Train Epoch: 4 [192000/441694 (43%)]	Loss: 0.501828
Train Epoch: 4 [204800/441694 (46%)]	Loss: 0.494068
Train Epoch: 4 [217600/441694 (49%)]	Loss: 0.507540
Train Epoch: 4 [230400/441694 (52%)]	Loss: 0.531628
Train Epoch: 4 [243200/441694 (55%)]	Loss: 0.524445
Train Epoch: 4 [256000/441694 (58%)]	Loss: 0.510980
Train Epoch: 4 [268800/441694 (61%)]	Loss: 0.520119
Train Epoch: 4 [281600/441694 (64%)]	Loss: 0.548488
Train Epoch: 4 [294400/441694 (67%)]	Loss: 0.544991
Train Epoch: 4 [307200/441694 (70%)]	Loss: 0.512553
Train Epoch: 4 [320000/441694 (72%)]	Loss: 0.510711
Train Epoch: 4 [332800/441694 (75%)]	Loss: 0.491322
Train Epoch: 4 [345600/441694 (78%)]	Loss: 0.526940
Train Epoch: 4 [358400/441694 (81%)]	Loss: 0.540244
Train Epoch: 4 [371200/441694 (84%)]	Loss: 0.483767
Train Epoch: 4 [384000/441694 (87%)]	Loss: 0.502915
Train Epoch: 4 [396800/441694 (90%)]	Loss: 0.476658
Train Epoch: 4 [409600/441694 (93%)]	Loss: 0.530647
Train Epoch: 4 [422400/441694 (96%)]	Loss: 0.480161
Train Epoch: 4 [435200/441694 (98%)]	Loss: 0.562513
slurmstepd: error: *** JOB 187474 ON ruche-gpu04 CANCELLED AT 2021-03-12T18:19:32 DUE TO TIME LIMIT ***
