# -*- coding: utf-8 -*-
"""OneShotLearning

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G-PWtkul5f588lP3RfpOwRtZ4ErQ3b4r

## One Shot Learning

### Imports
"""
from __future__ import print_function
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.autograd import Variable
from torch.utils.data import Dataset
import re
import sys
import pathlib
import numpy as np
import pandas as pd
import pickle
import random 

import logging
logging.basicConfig(level=logging.DEBUG,
    format='%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s',
                        datefmt='%a, %d %b %Y %H:%M:%S',
                        filename='./test.log',
                        filemode='w')

#data augmentation imports
from skimage import data
from skimage.transform import resize, rotate
from skimage.util import random_noise
from skimage import exposure
from skimage.color import rgb2gray
import scipy.ndimage as ndimage

import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

import os
# from google.colab import drive
# drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd drive/MyDrive/Projet Safran/
# %ls

"""### Preprocessing of the Data

#### Utilities
"""

def data_augmentation(original_image, new_size, rgb=False):
  if not rgb:
      original_image = rgb2gray(original_image)

  original_image = resize(original_image, (new_size[0], new_size[1]),anti_aliasing=True)

  list_augmentation = []

  #original if rgb and grey version if not
  list_augmentation.append(original_image)

  #rotations
  list_augmentation.append(rotate(original_image, 45))
  list_augmentation.append(rotate(original_image, 315))

  #random noise
  list_augmentation.append(random_noise(original_image))

  #horizontal flip
  list_augmentation.append(original_image[:, ::-1])

  #blured
  list_augmentation.append(ndimage.uniform_filter(original_image, size=(11)))

  #contrast 
  v_min, v_max = np.percentile(original_image, (0.2, 99.8))
  list_augmentation.append(exposure.rescale_intensity(original_image, in_range=(v_min, v_max)))


  return(list_augmentation)

def make_square(array_, size):
    array_size = array_.shape
    array_output = np.zeros((size[0], size[1]))
    array_output[0:array_size[0], 0:array_size[1]] = array_[0:array_size[0], 0:array_size[1]]
    return(array_output)

def crop_and_make_square(image, max_size,  size, fill_color=(0, 0, 0, 0)):

    size_image = image.shape
    
    if size_image[0]>=max_size[0]:

      if size_image[1]>max_size[1]:
        test = image[0:max_size[0],0:max_size[1]]

        return(make_square(test, size))

      cropped = image[0:size_image[0], :]
      return(make_square(cropped, size))
    elif size_image[1]>=max_size[1]:
        cropped = image[0:size_image[1]]
        return(make_square(cropped, size))

    else:
        return(make_square(image, size))

def show_image(before):
    fig, axes = plt.subplots(nrows=1, ncols=2)
    ax = axes.ravel()
    ax[0].imshow(before, cmap='gray')
    ax[0].set_title("Image")      
    ax[0].axis('off')
    ax[1].axis('off')
    plt.tight_layout()

"""#### Main Preprocessing"""

def transform_data(input_path, path_output,path_output_csv, new_size,  rgb=False, resize=False, ):

  try:
    os.mkdir(path_output)
  except:
    pass
  list_for_outputs = []
  r=0
  j=0
  for folder in os.listdir(input_path):
      print("___________________")
      print(folder)
      
      for imgname in os.listdir(input_path+folder):
          print("- - - - - - - - - - - - -")
          print(imgname)

          #path_picture = "/point_"+str(int_)+"_caption_"+str(j)
          #os.mkdir(path_output+path_picture)
          
          original_image = plt.imread(input_path+folder+'/'+imgname)
          
          images = data_augmentation(original_image, new_size, rgb)
          original_image=True
          for image in images:
            image_to_save = crop_and_make_square(image, new_size,  new_size)
            r+=1
            #show_image(image_to_save)

            plt.imsave(path_output+'/'+ str(r)+'.jpg', image_to_save, cmap='gray')
            list_for_outputs.append([str(r)+'.jpg', j, original_image])
            if original_image:
              original_image=False

      j+=1

  df = pd.DataFrame(list_for_outputs, columns= ['path', 'class', 'original_image'])
  df.to_csv(path_output_csv+ './output.csv')
  return df

# ls

# df = transform_data("./photos_apprentissage/", './data/','', new_size=[250,250], rgb=False)

# df.to_csv('./output.csv')

"""### Processing DataSet & DataLoader"""


# generate random integer values
from random import randint

"""#### Custom Dataset Class"""

# class CustomDataset(Dataset):
#     """Segmentation & Classification dataset."""

#     def __init__(self, folder_inputs,path_csv,list_indexes, transform=None, train=True):
#         """
#         Args:
#             folder_outputs (string): Path to the folder with.
#             root_dir (string): Directory with all the images.
#             transform (callable, optional): Optional transform to be applied
#                 on a sample.
#         """
#         self.data_output = pd.read_csv(path_csv)
#         self.folder_inputs = folder_inputs
#         self.list_indexes = list_indexes

#         if train:
#           self.inputs, self.landmarks = self.generate_random_dataset()
#         else:
#           self.inputs, self.landmarks = self.generate_all_pairs()


#         self.transform = transform

#     def generate_random_dataset(self):
#         df_output = self.data_output.iloc[self.list_indexes, :]
#         pairs = []
#         output = []
#         for class_ in set(df_output['class'].values):
#             df_int = df_output[df_output['class']==class_]
#             filenames = list(df_int['path'].values)
#             for i in range(len(filenames)):
#               for j in range(i+1, len(filenames)):
#                   output.append(1)
#                   pairs.append([filenames[i], filenames[j]])

#         filenames = list(df_output['path'].values)

#         for i in range(len(pairs)):
#             first_file = filenames[randint(0, len(filenames)-1)]
#             class_first_file = int(df_output[df_output['path'] == first_file]['class'].values)
#             list_second_file = list(df_output[df_output['class'] != class_first_file]['path'].values)
#             output.append(0)
#             pairs.append([first_file, list_second_file[randint(0, len(list_second_file)-1)]])
        
#         return(pairs, output)

#     def generate_all_pairs(self):
#       df_output = self.data_output.iloc[self.list_indexes, :]
#       pairs = []
#       output = []
#       filenames = df_output['path'].values
#       for i in range(len(filenames)):
#         for j in range(i+1, len(filenames)):
#             if len(set(df_output[(df_output['path'] == filenames[i]) | (df_output['path'] == filenames[j])]['class'].values))==1:
#               output.append(1)
#             else: 
#               output.append(0)
#             pairs.append([filenames[i], filenames[j]])

#       return(pairs, output)


#     def __len__(self):
#         return len(self.landmarks)

#     def __getitem__(self, idx):
#         if torch.is_tensor(idx):
#             idx = idx.tolist()[0]
        

#         landmarks = [self.landmarks[idx]]
#         image1 = rgb2gray(plt.imread(self.folder_inputs+self.inputs[idx][0]))
#         image2 = rgb2gray(plt.imread(self.folder_inputs+self.inputs[idx][1]))

#         pair = np.zeros([2,image2.shape[0], image2.shape[1]])  # 2 is for pairs

#         pair[0, :, :] = image1
#         pair[1, :, :] = image2

#         landmarks = np.array([landmarks])

#         if self.transform:
#             pair = self.transform(pair)
#             pair = torch.transpose(pair, 0, 1)

#             landmarks = self.transform(landmarks)
            
#         return pair, landmarks

class CustomDataset(Dataset):
    """Segmentation & Classification dataset."""

    def __init__(self, folder_inputs,path_csv,list_indexes, transform=None, train=True):
        """
        Args:
            folder_outputs (string): Path to the folder with.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.data_output = pd.read_csv(path_csv)
        self.folder_inputs = folder_inputs
        self.list_indexes = list_indexes
        self.max_nb_false_pair=40

        if train:
          self.inputs, self.landmarks = self.generate_random_dataset()
        else:
          self.inputs, self.landmarks = self.generate_all_pairs()


        self.transform = transform

    def generate_random_dataset(self):
        df_output = self.data_output.iloc[self.list_indexes, :]
        pairs = []
        output = []
        for class_ in set(df_output['class'].values):
            df_int = df_output[df_output['class']==class_]
            filenames = list(df_int['path'].values)
            for i in range(len(filenames)):
              #for j in range(i+1, len(filenames)):
              for j in range(i+1, min(len(filenames),i+1+self.max_nb_false_pair)):
                  output.append(1)
                  pairs.append([filenames[i], filenames[j]])

        filenames = list(df_output['path'].values)

        for i in range(len(pairs)):
            first_file = filenames[randint(0, len(filenames)-1)]
            class_first_file = int(df_output[df_output['path'] == first_file]['class'].values)
            list_second_file = list(df_output[df_output['class'] != class_first_file]['path'].values)
            output.append(0)
            pairs.append([first_file, list_second_file[randint(0, len(list_second_file)-1)]])
        
        return(pairs, output)

    def generate_all_pairs(self):
      df_output = self.data_output.iloc[self.list_indexes, :]
      pairs = []
      output = []
      filenames = df_output['path'].values
      for i in range(len(filenames)):
        #for j in range(i+1, len(filenames)):
        for j in range(i+1, min(len(filenames),1+i+self.max_nb_false_pair)):
            if len(set(df_output[(df_output['path'] == filenames[i]) | (df_output['path'] == filenames[j])]['class'].values))==1:
              output.append(1)
            else: 
              output.append(0)
            pairs.append([filenames[i], filenames[j]])

      return(pairs, output)


    def __len__(self):
        return len(self.landmarks)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()[0]
        

        landmarks = [self.landmarks[idx]]
        image1 = rgb2gray(plt.imread(self.folder_inputs+self.inputs[idx][0]))
        image2 = rgb2gray(plt.imread(self.folder_inputs+self.inputs[idx][1]))

        pair = np.zeros([2,image2.shape[0], image2.shape[1]])  # 2 is for pairs

        pair[0, :, :] = image1
        pair[1, :, :] = image2

        landmarks = np.array([landmarks])

        if self.transform:
            pair = self.transform(pair)
            pair = torch.transpose(pair, 0, 1)

            landmarks = self.transform(landmarks)
            
        return pair, landmarks


"""#### Custom DataLoaders"""

def train_split_dataset(folder_inputs,path_csv, transform=None,size_split=[], train=True):
  datasets = []
  number_indexes = len(pd.read_csv(path_csv))
  list_indexes = [i for i in range(number_indexes)]
  if train:
      train_dataset = CustomDataset(folder_inputs,path_csv,list_indexes, transform, True)
      datasets = [train_dataset]
  else:
      random.shuffle(list_indexes)

      train_indexes = list_indexes[0: int(size_split[0]*len(list_indexes))]
      test_indexes = list_indexes[int(size_split[0]*len(list_indexes)):]

      train_dataset = CustomDataset(folder_inputs,path_csv,train_indexes, transform, True)
      test_dataset = CustomDataset(folder_inputs,path_csv,test_indexes, transform, False)
      datasets = [train_dataset, test_dataset]

  return(datasets)

def get_dataloaders(folder_inputs,path_csv, batch_size, transform=None,size_split=[], train=True):
  dataloaders = []
  datasets = train_split_dataset(folder_inputs,path_csv, transform,size_split, train)
  train_loader = torch.utils.data.DataLoader(datasets[0], batch_size=batch_size, shuffle=True, num_workers=0)
  if train:
      return([train_loader])
  else:
      test_loader = torch.utils.data.DataLoader(datasets[1], batch_size=batch_size, shuffle=True, num_workers=0)
      return([train_loader, test_loader])

"""### Model & utilities

#### Siamese Class
"""

class SiameseNetwork(nn.Module):
    def __init__(self, image_size, device):
        super(SiameseNetwork, self).__init__()
        self.image_size = image_size
        self.device = device
        
        # Layer 1
        self.conv_1 = nn.Conv2d(in_channels=self.image_size[0], out_channels= 4, kernel_size= 3,padding=1)  
        self.activation_1 = nn.ReLU()
        self.max_pooling_1 = nn.MaxPool2d((5, 5))
        self.dropout_1 = nn.Dropout(p=0.25)

        #layer 2
        self.conv_2 = nn.Conv2d(in_channels= 4, out_channels= 8, kernel_size= 3,padding=1)  
        self.activation_2 = nn.ReLU()
        self.max_pooling_2 = nn.MaxPool2d((5, 5))
        self.dropout_2 = nn.Dropout(p=0.25)

        #layer 3
        self.conv_3 = nn.Conv2d(in_channels= 8, out_channels= 8, kernel_size= 3,padding=1)  
        self.activation_3 = nn.ReLU()
        self.max_pooling_3 = nn.MaxPool2d((2, 2))
        self.dropout_3 = nn.Dropout(p=0.25)    

        # layer 4
        self.linear_4 = nn.Linear(200, 100)
        self.activation_4 = nn.ReLU()

        # layer 5: output
        self.linear_5 = nn.Linear(100, 2)

        

    def forward(self,x):
        # print("mem free: {} Mb".format(get_gpu_memory(self.cuda_id)))
        #print('in', x.shape)
        x = x.float()
        #layer 1
        x = self.conv_1(x)
        #print('1', x.shape)
        x = self.activation_1(x)
        x = self.max_pooling_1(x)
        x = self.dropout_1(x)

        #layer 2
        x = self.conv_2(x)
        #print('2', x.shape)
        x = self.activation_2(x)
        x = self.max_pooling_2(x)
        x = self.dropout_2(x)
        
        #layer 3
        x = self.conv_3(x)
        #print('3', x.shape)
        x = self.activation_3(x)
        x = self.max_pooling_3(x)
        x = self.dropout_3(x)
        
        #layer 4
        #print('4', x.shape)
        x = x.view(x.size()[0],-1)
        x = self.linear_4(x)
        x = self.activation_4(x)
        
        #layer 5: output
        #print('5', x.shape)
        x = self.linear_5(x)
        x = F.softmax(x, dim=1)
        #print('output', x.shape)
        return  x

"""#### Utilities"""

def train(epoch, network, loader, optimizer, device):
    network.train()
    for batch_idx, (data, target) in enumerate(loader):
        data = data.to(device)
        target = target.to(device)
        optimizer.zero_grad()
        output = network(data)
        target_int = torch.flatten(target, start_dim=0)
        loss = F.cross_entropy(output, target_int)
        loss.backward()
        optimizer.step()
        if batch_idx % 100 == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * len(data), len(loader.dataset),
                100. * batch_idx / len(loader), loss.item()))
    return loss

def test(network, loader, optimizer, device, set_):
    network.eval()
    test_loss = 0
    correct = 0

    for batch_idx, (data, target) in enumerate(loader):
        data = data.to(device)
        target = target.to(device)
        target_int = torch.flatten(target, start_dim=0)

        output = network(data) #TODO: split in smaller batch https://discuss.pytorch.org/t/how-to-fix-runtimeerror-cuda-out-of-memory/106818
        test_loss += F.cross_entropy(output, target_int).item()

        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability
        # print(pred)
        correct += pred.eq(target_int.data.view_as(pred)).cpu().sum()

    test_loss /= len(loader.dataset)
    print('\n '+set_+ ' set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(loader.dataset),
        100. * correct / (len(loader.dataset))))
    return(100. * correct / (len(loader.dataset)))

"""#### Execution"""

if __name__ == "__main__":

    photos = os.path.abspath(sys.argv[1])+"/"
    data_photos = os.path.abspath(sys.argv[2])
    output = os.path.abspath(sys.argv[3])+"/"
    print(photos, data_photos, output)
    # df = transform_data("./photos_apprentissage/", './data/','', new_size=[250,250], rgb=False)
    # df = transform_data(photos, output,'', new_size=[250,250], rgb=False)
    # df.to_csv('./output.csv')

    # data_transform = transforms.Compose([transforms.ToTensor()])
    # dataloaders = get_dataloaders(output,data_photos, 20, data_transform, [0.95, 0.05], False)

    # ##### PARAMETERS ######    

    # batch_size = 20
    # epochs = 1
    # lr = 0.01

    # ##### INITIALIZATION ######   
    # device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    # #device = "cpu"
    # print('device :',device)
    # loader = dataloaders[0]

    # network = SiameseNetwork([2, 250, 250], device)

    # optimizer = optim.SGD(network.parameters(), lr=lr)
    # optimizer = optim.Adam(network.parameters(), lr=lr)
    # loader = dataloaders[0]
    # network.to(device)

    # ##### TRAINING #####
    # for epoch in range(epochs):
    #     train(epoch, network, loader, optimizer, device)

    # torch.save(network, "./model.torch")

    # test(network, dataloaders[0], optimizer, device, set_='train')

    # test(network, dataloaders[1], optimizer, device, set_='test')
    

    # """### GridSearch"""

    def grid_search(batch_size_list, epochs_list, lr_list, path_input, 
                    path_csv_output, size_split, size_picture):

        ##### INITIALIZATION ######   
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        # device = "cpu"
        print('device :',device)
        dict_results = {}

        print('##############################')
        for batch_size in batch_size_list:

            data_transform = transforms.Compose([transforms.ToTensor()])
            dataloaders = get_dataloaders(path_input,path_csv_output, batch_size, data_transform, size_split, False)

            train_loader, test_loader = dataloaders[0], dataloaders[1]

            for epochs in epochs_list:
                for lr in lr_list:
                    #torch.cuda.empty_cache()

                    print('Working on model = ', ' batch size: '+str(batch_size)+' epochs: '+str(epochs) +' lr: '+str(lr))
                    print(size_picture, device)
                    network = SiameseNetwork(size_picture, device).to(device)
                    torch.save(network, "./model.torch")
                    optimizer = optim.SGD(network.parameters(), lr=lr)

                    ##### TRAINING #####
                    for epoch in range(epochs):
                        loss = train(epoch, network, train_loader, optimizer, device) #TODO: loss final après entrainement à stocker
                        
                    dict_results['model :'+str(batch_size)+' '+str(epochs) +' '+str(lr)]= [test(network, train_loader, optimizer, device, 'train'), test(network, test_loader, optimizer, device, 'test')]
                    print(output)
                    # torch.save(network.state_dict(), output + 'model'+str(batch_size)+str(epochs)+str(lr)+'.pt')
                    torch.save(network.state_dict(), '/gpfs/workdir/dunoyerg/models/' + 'model'+str(batch_size)+str(epochs)+str(lr)+'.pt')
                    
                    del network
                    print('________________________________________')

        return(dict_results)



    # print(grid_search([20], [20], [0.1], photos, 
    #                 './output.csv', [0.95, 0.05], [2, 250, 250]))

    print(grid_search([1], [1], [0.1], photos, 
                    data_photos, [0.95, 0.05], [2, 250, 250]))